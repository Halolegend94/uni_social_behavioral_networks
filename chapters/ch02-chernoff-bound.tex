\chapter{Chernoff Bound}

In this Chapter we see a way to bound tail distributions, that is, the probability that a random variable assumes values that are far from its expectation.

We state (without proof) the Chernoff Bound, which is a powerful tool to bound tail distribution exponentially decreasing values.
\begin{thm}[Chernoff Bound]
	Let $X_1, X_2, \ldots, X_n$, $0 \leq X_i \leq 1,\forall i$, be a set of mutually independent random variables, and $X = \sum_{i=1}^nX_i$. Then
	\begin{equation}
	\pr{X \leq (1-\varepsilon)E[X]} \leq e^{-\frac{\varepsilon^2E[X]}{3}}
	\end{equation}
	
	and
	\begin{equation}
	\pr{X \geq (1+\varepsilon)E[X]} \leq e^{-\frac{\varepsilon^2E[X]}{3}}.
	\end{equation}
\end{thm}

Consider the following situation. We flip $n$ fair coins. Define
\[X_i = \begin{cases}1 \textit{ if the i-th flip results in heads}\\0 \textit{ otherwise}\end{cases}\]

then 
\[X = \sum_{i=1}^n = \textit{ \# of heads}.\] 

What is the probability of the event $\{X = k\}$. For $X$ to be $k$ there must be exactly $k$ coins which resulted in heads. We can choose among $\binom{n}{k}$ compatible events (set of variables), each having the same probability $2^{-n}$ to happen. It follows that
\begin{equation*}
	\pr{X = k} = \binom{n}{k}2^{-n}.
\end{equation*} 

What if the coin is not fair? We have the binomial distribution.

\begin{equation}
	\pr{X = k} = \binom{n}{k} p^k(1-p)^{n-k}.
\end{equation}

We would like to know what is the probability that $X$ assumes a value far from the expected one. We can use the Chernoff Bound.

\begin{equation}
	\pr{X \leq (1-\varepsilon)np} \leq e^{-\frac{\varepsilon pn}{3}},
\end{equation}

Suppose we choose $p = \frac{1}{2}$ and
\begin{equation}
	\varepsilon = \sqrt{\frac{\log n}{n}}
\end{equation}

Then we have
\[e^{-\frac{\frac{\log n}{n}\frac{1}{2}n}{3}} = e^{-\frac{1}{6}\log n} = \frac{1}{\sqrt[6]{n}}.\]

That is, the probability of error can be made as tiny as we want by increasing $n$.

\section{Chain letters}

Chain letters are (were) online petitions that spread virally through emails. They work in the following way. The petition's creator writes an email explaining a certain problem he or she wants to address. Then he/she signs the petition, sends it to a set of recipients and ask them to sign and forward the email. Some recipients may ignore the email, others may sign and forward it instead. One can model the spread using a tree $T$, where the root is the petition's creator and every node has a child for each person he forwarded the email to. Of course, email are privates. For an external observer to know the petition, at least one person must post the email on a public accessible place on the Web (e.g. public mailing lists). When a node $v$ (person) \emph{exposes} itself (i.e. publish the email), all its ancestors in the tree are revealed too (the path from the root to $v$).

We would like to know some information about the spread process, such as the reach of the petition. The full tree $T$ is in general unknown, and what can be observed of it depends on how many and which nodes get exposed. We can assume that there exists a small probability $\delta > 0$ such that every node $v \in T$ gets exposed independently with that probability. Define $T_\delta$ to be the visible part of $T$ reconstructed though the exposed nodes. Let $V$ be the set of nodes in $T_\delta$. Define $E \subseteq V$ to be the set of nodes that exposed themselves by disclosing their email to the public. Finally, let $L \subseteq E$ be the set of leaves in $T_\delta$.

As we said, we would like to know $|V| = n$, but we only have $E$. Can we estimate $n$? If we assume that each node in $E$ exposed itself independently from the others, we can make a reasonable guess about $n$ by looking at $T_\delta$ \cite{chainletters}. In fact
\begin{equation}
 n\delta = |E|
\end{equation}
so 
\begin{equation}
n= \frac{|E|}{\delta}.
\end{equation}

At this point, we need to find $\delta'$ such that $\delta' \approx \delta$. One can wrongly think that
\begin{equation}
	\delta' = \frac{|E|}{|T_\delta|}.
\end{equation}

The problem here are the leaves of $T_\delta$. If they hadn't exposed themselves, we wouldn't know about them (or other nodes). From the point of view of $T_\delta$, they are \emph{not} exposed independently with probability $\delta'$; rather, they are exposed with probability $1$. To compute $\delta'$ then, we excludes $T_\delta$'s leaves. What follows is an algorithm that outputs $\delta'$.

\begin{algorithm}
\textbf{Input:} $E, L, V$.\\
\If{$|V| = 0$}{\Return $0$}
\If{$|V| = 1$}{\Return $1$}
\Return $\frac{|E| - |L|}{|V|-|L|}$

\caption{Estimation of $\delta$}
\end{algorithm}

Finally, if $|V| \geq 2$,

\begin{equation}
	 n \approx \frac{|E|}{\delta'}.
\end{equation}

\begin{lem}
	If $|V| \geq 2$ then
	\begin{equation}
	\pr{|\delta' - \delta| \geq \epsilon\delta} \leq 2e^{\frac{1}{3}\epsilon^2\delta|V-L|}.
	\end{equation}
\end{lem}
\begin{proof}
	For each node $i$, let $X_i$ be a random variable such that
	\begin{equation}
		X_i = \begin{cases}
		1 \textit{ if node i exposes itself}\\
		0 \textit{ otherwise}.
		\end{cases}
	\end{equation}
	
	Consider the three sets $A$, $B$ and $C$ built in the following way. We can scan the original tree in a bottom up fashion. At a certain time, node $i$ is considered. If $i \not\in A$, check if the node was exposed. If $X_i = 1$, add $i$ to $B$ and every its ancestor to $A$; otherwise, add $i$ to $C$. 
	Observe that the tripartition process does not disclose the value of $X_i$ for all $i \in A$, and that $A = V - L$ and thus the set $E - L$ coincides with the set of exposed nodes in $A$. Then, we can apply the Chernoff bound, having $X = |E - L|$.
	
	\begin{align}
		\pr{X \geq (1 + \epsilon)\delta |A|} &= \pr{|E - L| \geq |A|\delta + \epsilon\delta|A|}\\
		&=\pr{\frac{|E - L|}{|A|} \geq \delta + \epsilon\delta}\\
		&=\pr{|\delta'-\delta| \geq \epsilon\delta} \tag{We want the difference small enough}\\
		&= \pr{|X - |A|\delta| \geq \epsilon\delta|A|}\\
		&\leq 2e^{-\frac{1}{3}\epsilon^2E[X]}\\
		& = 2e^{-\frac{1}{3}\epsilon^2\delta|V-L|}.
		\end{align}	
\end{proof}

